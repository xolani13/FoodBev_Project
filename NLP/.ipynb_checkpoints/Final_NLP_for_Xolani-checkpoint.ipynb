{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import spacy\n",
    "from spacy.tokens import doc\n",
    "import enchant\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "directory=os.listdir(r'C:\\Users\\Ralph\\Downloads\\Ralph NLP')\n",
    "is_pdf=[]\n",
    "for pdfs in directory:\n",
    "    if pdfs.endswith('.pdf'):\n",
    "        is_pdf.append(pdfs)\n",
    "print(is_pdf)\n",
    "\n",
    "for i in range(0, len(is_pdf)-1, 1):\n",
    "    pdf = pdfplumber.open(is_pdf[i])\n",
    "    for page in pdf.pages:\n",
    "        text = str(page.extract_text())\n",
    "       \n",
    "        with open(str(''.join(e for e in is_pdf[i] if (e.isalnum() or e.isspace()))) +\".txt\", 'a', encoding='utf-8') as fp:\n",
    "            fp.write(str(text))\n",
    "\n",
    "is_txt_file=[]\n",
    "directory=os.listdir(r'C:\\Users\\Ralph\\Downloads\\Ralph NLP')\n",
    "for txt_file in directory:\n",
    "    if txt_file.endswith('.txt'):\n",
    "        is_txt_file.append(txt_file)\n",
    "\n",
    "for k in range(0, len(is_txt_file)-1, 1):\n",
    "    \n",
    "    myfile = open(str(is_txt_file[k]), 'r' , encoding='utf-8')\n",
    "    print('File name : ' + str(is_txt_file[k]))\n",
    "    print('This is file number ' + str(k+1)+ ' in the directory')\n",
    "   \n",
    "\n",
    "    raw_txt = myfile.read()\n",
    "\n",
    "    doc = nlp(raw_txt)\n",
    "\n",
    "    word_count_dict = {}\n",
    "    word_count_dict['NOUN'] = {}\n",
    "    word_count_dict['PROPN'] = {}\n",
    "    word_count_dict['ADJ'] = {}\n",
    "    word_count_dict['VERB'] = {}\n",
    "\n",
    "    for token in doc: \n",
    "        \n",
    "        part_of_speech = token.pos_\n",
    "        if part_of_speech in ['NOUN', 'PROPN', 'ADJ', 'VERB'] and token.is_stop == False:\n",
    "            word_lemma = token.lemma_\n",
    "\n",
    "            new_word=''.join(e for e in word_lemma if (e.isalnum() or e.isspace()))\n",
    "            American_English= enchant.Dict(\"en_US\")\n",
    "            British_English= enchant.Dict(\"en_GB\")\n",
    "            \n",
    "            if len(new_word)<=2:\n",
    "                pass\n",
    "            elif new_word.isdigit()==True:\n",
    "                pass\n",
    "\n",
    "            elif British_English.check(new_word)==True or American_English.check(new_word)==True:\n",
    "                current_count = word_count_dict[part_of_speech].get(new_word, 0)\n",
    "\n",
    "                current_count += 1\n",
    "                word_count_dict[part_of_speech][new_word] = current_count\n",
    "                df=pd.DataFrame.from_dict(word_count_dict)\n",
    "                df.sort_values('NOUN', inplace=True, ascending=False)\n",
    "                df=df.head(15)\n",
    "                df2=pd.DataFrame.from_dict(word_count_dict)\n",
    "                df2.sort_values('ADJ', inplace=True, ascending=False)\n",
    "                df2=df2.head(15)\n",
    "                df3=pd.DataFrame.from_dict(word_count_dict)\n",
    "                df3.sort_values('PROPN', inplace=True, ascending=False)\n",
    "                df3=df3.head(15)\n",
    "\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    print(df)\n",
    "    print(df2)\n",
    "    print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
